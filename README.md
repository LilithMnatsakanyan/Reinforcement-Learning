# **Reinforcement Learning Projects**

This repository contains a collection of hands-on **Reinforcement Learning (RL)** projects, each focused on implementing and analyzing different algorithms and environments from the textbook **Reinforcement Learning: An Introduction** by Sutton & Barto.

The goal of this repository is to develop a deeper understanding of:
- âœ… Agent learning and policy optimization
- âœ… Environment dynamics and reward mechanisms
- âœ… Exploration-exploitation tradeoffs
- âœ… On-policy vs. off-policy learning

---

## ğŸ§  **Projects Overview**

Each project explores a specific RL concept or algorithm, and includes its own `README.md` with:
- **Objectives** â€“ What the project aims to demonstrate
- **Methodology** â€“ Core algorithms and environment setup
- **Key Results** â€“ Visualizations, learning curves, and observations

---

## ğŸ“‚ **Current Projects**


- [tic-tac-toe](./tic-tac-toe/) â€“ Self-play using state-value learning
- [ten-armed-testbed](./ten-armed-testbed/) â€“ Multi-armed bandits with Îµ-greedy strategy
- [gridworld-dp](./gridworld-dp/) â€“ Policy evaluation and improvement using Dynamic Programming
- [gridworld-mdp](./gridworld-mdp/) â€“ MDP formulation and planning
- [gambler-problem](./gambler-problem/) â€“ Dynamic programming for optimal betting
- [blackjack](./blackjack/) â€“ Policy evaluation using Monte Carlo
- [infinite-variance](./infinite-variance/) â€“ Off-policy learning and variance analysis
- [random-walk](./random-walk/) â€“ TD(0) vs Monte Carlo prediction
- [windy-gridworld](./windy-gridworld/) â€“ SARSA learning in stochastic grid environment
- [cliff-walking](./cliff-walking/) â€“ Episodic control with Îµ-greedy and SARSA/Q-learning
- [maximization-bias](./maximization-bias/) â€“ Demonstrating maximization bias with Q-learning vs Double Q-learning

Each project may contain **notebooks**, **scripts**, and **configuration files** specific to its implementation.

---

## **ğŸš€ Getting Started** 
_(Example on tic-tac-toe project)_

### 1ï¸âƒ£ **Clone the Repository**
```sh
git clone https://github.com/LilithMnatsakanyan/tic-tac-toe.git  
cd tic-tac-toe
```

### 2ï¸âƒ£ **Install Dependencies**
```sh
pip install -r requirements.txt  
```

### 3ï¸âƒ£ **Train the RL Agent**
```sh
python src/tic-tac-toe.py  
```

### 4ï¸âƒ£ **Play the Game**

You can play Tic Tac Toe in two ways:

âœ… **Web-based interface** (Recommended):
```sh
python app.py  
```
Then open `index.html` in your browser to play against the AI.

âœ… **Console-based interface** (Using keyboard letters for a 3Ã—3 grid):
```sh
python src/tic-tac-toe.py  
```

---

## ğŸ“Œ **Key Topics Covered**

### ğŸ¯ Foundational Algorithms
- Multi-Armed Bandits (Action-Value Methods)
- Dynamic Programming (Policy Evaluation & Improvement)
- Monte Carlo Prediction and Control
- Temporal-Difference Learning (TD(0), SARSA, Q-Learning)
- Off-policy Learning and Variance (Importance Sampling)
- Double Q-Learning 

### ğŸ§ª Experimental Environments
- Tic-Tac-Toe
- Multi-Armed Bandits (Ten-Armed Testbed)
- Gridworld (DP and MDP Variants)
- Gambler's Problem
- Blackjack
- Infinite Variance
- Random Walk
- Windy Gridworld
- Cliff Walking
- Maximization Bias

---

## **ğŸ“š Dependencies & Tools**

This repository primarily uses:
- **Python 3.x**
- **NumPy, Pandas** (Data handling)
- **Matplotlib, Seaborn** (Visualization)
- **tqdm** (Progress bars for episode tracking)


---

## ğŸ“– **Reference**

> **Reinforcement Learning: An Introduction**  
> Richard S. Sutton & Andrew G. Barto  
> _Second Edition, 2018 â€“ MIT Press_  
> [Read online](https://www.andrew.cmu.edu/course/10-703/textbook/BartoSutton.pdf)

---

## ğŸ“¬ **Contact**

If you have any questions, feel free to reach out! ğŸ˜Š

ğŸ”— GitHub: [github.com/LilithMnatsakanyan](https://github.com/LilithMnatsakanyan)

---
