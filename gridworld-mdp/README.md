# **Reinforcement Learning: Gridworld MDP**

This project implements the **Gridworld Markov Decision Process (MDP)**, a fundamental environment in **Reinforcement Learning (RL)**. It is inspired by **Chapter 3: Finite Markov Decision Processes** from the book **Reinforcement Learning: An Introduction** by **Richard S. Sutton & Andrew G. Barto**.


---

## **ğŸ“‚ Project Structure**
```
gridworld-mdp/
â”‚â”€â”€ src/                      # Core implementation
â”‚   â”œâ”€â”€ grid_world.py         # Gridworld MDP implementation
â”‚â”€â”€ notebooks/                # Jupyter Notebooks for experimentation
â”‚   â”œâ”€â”€ grid_world.ipynb      
â”‚â”€â”€ book_images/              # Reference images from the book
â”‚   â”œâ”€â”€ Figure_3_2.PNG        # State-value function example from the book
â”‚   â”œâ”€â”€ Figure_3_5.PNG        # Optimal policy example from the book
â”‚â”€â”€ generated_images/         # Plots generated from simulations
â”‚   â”œâ”€â”€ figure_3_2.png        # Computed state-value function visualization
â”‚   â”œâ”€â”€ figure_3_5.png        # Computed policy iteration visualization
â”‚   â”œâ”€â”€ figure_3_5_policy.png # Computed optimal policy representation
â”‚â”€â”€ __init__.py  
â”‚â”€â”€ README.md                 # Project documentation
```
---

## ğŸ“Œ Key Features

âœ… Implements **Gridworld MDP**, a foundational RL environment.

âœ… Demonstrates **state-value functions, policy evaluation, and policy improvement**.

âœ… Includes **visualizations** to illustrate **value iteration and policy iteration**.

âœ… Supports **different reward structures** and **terminal states**.

âœ… Provides **notebooks for step-by-step exploration** of Gridworld concepts.

---

## ğŸ“Š Results and Insights

### 1ï¸âƒ£ **State-Value Function Visualization**
In **Gridworld**, an agent moves in a 2D grid with rewards assigned to different states. The **state-value function** determines how good it is for the agent to be in a given state.

ğŸ“ˆ **Example Visualization:**

<img src="generated_images/figure_3_2.png" width="400"/>


_This image represents the computed state-value function for the Gridworld MDP._

---

### 2ï¸âƒ£ **Optimal Policy Representation**
The optimal policy guides the agent towards maximizing cumulative rewards. The **policy iteration algorithm** refines policies iteratively until convergence.

ğŸ“ˆ **Example Visualization:**

<img src="generated_images/figure_3_5.png" width="400"/>

<img src="generated_images/figure_3_5_policy.png" width="400"/>


_This image showcases the computed optimal policy derived from policy iteration._

---

## ğŸ“¢ Conclusion

This project explores **Markov Decision Processes (MDPs)** in a **Gridworld environment**, demonstrating key RL concepts such as **policy evaluation, policy improvement, and value iteration**.

- **Value Iteration** efficiently finds the optimal policy.
- **Policy Iteration** alternates between policy evaluation and improvement.
- **State-value and action-value functions** guide the agent in decision-making.

By studying **Gridworld**, we build an intuition for **Dynamic Programming (DP)** techniques in Reinforcement Learning, paving the way for **more complex RL environments**.

---

