# **Reinforcement Learning: Random Walk with Function Approximation**

This project implements and compares various **function approximation (FA)** methods for solving the **1000-state Random Walk** problem.  
The experiments are based on **Chapter 9: On-Policy Prediction with Approximation** from the book *Reinforcement Learning: An Introduction* by **Richard S. Sutton** and **Andrew G. Barto**.


---

## ğŸ“‚ **Project Structure**
```
function-approximation/
â”œâ”€â”€ src/
â”‚ â””â”€â”€ random_walk.py # Core logic for environment dynamics and function approximation methods
â”œâ”€â”€ notebooks/ # Jupyter Notebooks for experiments and analysis
â”‚ â”œâ”€â”€ bootstrapping.ipynb
â”‚ â”œâ”€â”€ polynomials_vs_fourier.ipynb
â”‚ â”œâ”€â”€ state_aggregation.ipynb
â”‚ â””â”€â”€ tile_coding.ipynb
â”œâ”€â”€ book_images/ # Reference figures from Sutton & Barto (Chapter 9)
â”‚ â”œâ”€â”€ Figure_9_1.PNG
â”‚ â”œâ”€â”€ Figure_9_2.PNG
â”‚ â”œâ”€â”€ Figure_9_5.PNG
â”‚ â””â”€â”€ Figure_9_10.PNG
â”œâ”€â”€ generated_images/ # Plots generated from simulations
â”‚ â”œâ”€â”€ figure_9_1.png
â”‚ â”œâ”€â”€ figure_9_2.png
â”‚ â”œâ”€â”€ figure_9_5.png
â”‚ â””â”€â”€ figure_9_10.png
â””â”€â”€ README.md # Project documentation
```

---

## ğŸ“Œ **Key Features**
âœ… Implements the **1000-state continuous Random Walk** environment.  
âœ… Compares multiple **function approximation methods**:
- State Aggregation (Gradient MC & Semi-gradient TD)
- Polynomial Basis
- Fourier Basis
- Tile Coding  
  âœ… Evaluates performance using **Root Mean Squared Error (RMSE)** against true state values.  
  âœ… Reproduces **key figures from Chapter 9** of Sutton & Barto, demonstrating each methodâ€™s properties.

---

## âš™ï¸ **Environment Overview**
- **Environment:** Continuous 1D random walk with **1000 states** (numbered 1â€“1000).
- **Terminal States:** 0 (left) and 1001 (right).
- **Start State:** Always begins at **State 500**.
- **Actions:** Move left or right by a random integer step from {1, 2, â€¦, 100}.
- **Rewards:**
    - +1 for reaching the right terminal state (1001)
    - -1 for reaching the left terminal state (0)
    - 0 for all other transitions

---

## ğŸ§  **Learning Algorithms & Function Approximators**
This project uses **Gradient Monte Carlo (MC)** and **Semi-gradient TD(0)** to learn an approximate value function **vÌ‚(s, w)**.

### ğŸ”· **Gradient Monte Carlo (MC)**
Updates weights after each episode completes.  
Equation:  
**w â† w + Î± Ã— (G âˆ’ vÌ‚(S, w)) Ã— âˆ‡vÌ‚(S, w)**

### ğŸ”´ **Semi-gradient TD(0)**
Updates weights at each step using bootstrapping.  
Equation:  
**w â† w + Î± Ã— (R + Î³vÌ‚(Sâ€², w) âˆ’ vÌ‚(S, w)) Ã— âˆ‡vÌ‚(S, w)**

---

### âš™ï¸ **Function Approximation Methods**
Four methods are used to represent the feature vector **x(s)**:

- **State Aggregation:**  
  Groups 1000 states into 10 equal bins of 100 states.  
  Each feature vector is a one-hot encoding of its group.

- **Polynomial Basis:**  
  Represents normalized state position with polynomial features:  
  **x(s) = (1, s, sÂ², â€¦, sâ¿)**

- **Fourier Basis:**  
  Represents state features using cosine terms:  
  **x(s) = (cos(0Ï€s), cos(1Ï€s), â€¦, cos(nÏ€s))**

- **Tile Coding:**  
  Uses multiple overlapping tilings (coarse coding) to produce a sparse binary feature vector, improving generalization.

---

## ğŸ“Š **Results and Visualizations**

### 1ï¸âƒ£ **Figures from Suttonâ€™s Book**
These serve as theoretical baselines for comparison.

ğŸ“ˆ **Reference Figures:**  
<img src="./book_images/Figure_9_1.PNG" alt="Sutton Fig 9.1" width="400"/>  
<img src="./book_images/Figure_9_2.PNG" alt="Sutton Fig 9.2" width="400"/>  
<img src="./book_images/Figure_9_5.PNG" alt="Sutton Fig 9.5" width="400"/>  
<img src="./book_images/Figure_9_10.PNG" alt="Sutton Fig 9.10" width="400"/>

---

### 2ï¸âƒ£ **Generated Simulation Results**
Replications of Suttonâ€™s experiments using implemented methods.

ğŸ“ˆ **Generated Figures:**  
<img src="./generated_images/figure_9_1.png" alt="State Aggregation Results" width="400"/>  
<img src="./generated_images/figure_9_2.png" alt="Bootstrapping Results" width="400"/>  
<img src="./generated_images/figure_9_5.png" alt="Polynomial vs Fourier Basis" width="400"/>  
<img src="./generated_images/figure_9_10.png" alt="Tile Coding Results" width="400"/>

---

## ğŸ” **Interpretation of Results**
- **State Aggregation (Fig. 9.1):**  
  Gradient MC converges to a stepwise approximation of the true value.  
  Lowest error in the middle of groups, highest at boundaries.

- **Bootstrapping (Fig. 9.2):**  
  Semi-gradient TD(0) learns faster but converges to a biased estimate.  
  *n*-step TD methods help balance bias and variance.

- **Polynomial vs. Fourier Basis (Fig. 9.5):**  
  Fourier basis outperforms polynomial.  
  Polynomial features can cause instability due to correlation and large magnitudes.  
  Fourier provides smoother, stable generalization.

- **Tile Coding (Fig. 9.10):**  
  Multiple overlapping tilings yield better learning and generalization.  
  Updates affect neighboring states, accelerating convergence.

---

## ğŸ“¢ **Conclusion**
This project demonstrates the **strengths and trade-offs** of different function approximation techniques in continuous state spaces.

- **State Aggregation:** Simple but limited representational capacity.
- **TD Bootstrapping:** Faster but introduces bias.
- **Feature Design:** Crucial for stability â€” Fourier basis > Polynomial.
- **Tile Coding:** Offers powerful and efficient generalization for RL tasks.

These experiments provide practical insight into the principles of **function approximation**, showcasing the importance of representation and learning stability as discussed in **Chapter 9 of Sutton & Bartoâ€™s book**.

---
